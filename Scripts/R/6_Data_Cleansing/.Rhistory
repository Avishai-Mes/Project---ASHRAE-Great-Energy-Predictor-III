mnar
# examination of missingness mechanism using 'glm'
# For runtime considerations, I will take a random sample of data
set.seed(2)
sample_df <- ff_train_agg %>% slice_sample(n = 2000)
# n = 2000, runtime - 3 min
ff_train_agg_na_sample <- missingMatrix(sample_df)
res4 <- NULL
for(m in mm$missingness$var) {
ff <- sample_df
# change the current examined variable values with its missing indicators
ff[[m]] <- ff_train_agg_na_sample[[m]]
mod <- glm(ff[[m]] ~., data = ff, family = "binomial", maxit = 100)
sm <- summary(mod)
if(is.null(sm) == F) {  # a check
sm1 <- data.frame(var = row.names(sm$coefficients), pvalue = sm$coefficients[, 4])
res4 <- rbind(res4, cbind(m, sm1))
# append(res4, sm, m)
} else {
print(sm)
}
}
row.names(res4) <- NULL
res4
res4 %>% filter(pvalue <= 0.05)
sample_df <- ff_train_agg %>% select(-date)
sample_df
# Import of packages
library(readr)
library(visdat)
library(dplyr)
library(ggplot2)
library(psych)
library(odbc)
library(DBI)
library(dbscan)
library(naniar)
library(cocor)
library(gridExtra)
library(corrgram)
# 'mechkar' - written by Tomas Carpati
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/mechkar.R")
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/utils.R")
ff_train_agg <- data.frame(read.csv("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Data/CheckPoint2/ff_train_agg.csv"))
# nominal columns
nominal <- c("site_id", "building_id",
# all variables that start with 'sw' or 'is' (binary variables)
names(ff_train_agg)[grepl('^(sw|is)', names(ff_train_agg))])
# Cyclical variables (contain "_x_" or "_y_")
cyclical_vars <- names(ff_train_agg)[grep("_x_|_y_", names(ff_train_agg))]
# Excluding variables that outliers check is not relevant to them
vars_for_outliers <- names(ff_train_agg)[!names(ff_train_agg) %in% c(nominal, cyclical_vars, 'date')]
res1 <- NULL
outmat <- outlierMatrix(ff_train_agg)
# Excluding variables that outliers check is not relevant to them
for(n in vars_for_outliers){
n_out <- ff_train_agg[[n]]                           # 'n_out' includes outliers
n_non <- ff_train_agg[[n]][which(outmat[[n]] == 0)]  # 'which' returns indices
outnum <- length(n_out) - length(n_non)
pval <- suppressWarnings(ks.test(n_out, n_non)$p.value)
res1 <- rbind(res1, cbind(var = n, outliers_num = outnum,
distribution_changed = ifelse(pval < 0.05, "+", "-")))
}
res1
res2 <- NULL
outmat <- outlierMatrix(ff_train_agg)
# Excluding variables that outliers check is not relevant to them
for(n in vars_for_outliers){
out <- ff_train_agg[[n]]                         # data including outliers
non <- ff_train_agg[[n]][which(outmat[[n]] == 0)]  # data excluding outliers
# make sure that SD !=0 for the use of 'cocor' function
if(length(unique(non)) <= 1){next}
meter_reading_sum_out <- ff_train_agg$meter_reading_sum                # outcome including outliers
meter_reading_sum_non <- meter_reading_sum_out[which(outmat[[n]] == 0)]  # outcome excluding outliers
outdf <- data.frame(x_out = out,y_out = meter_reading_sum_out)
nondf <- data.frame(x_non = non,y_non = meter_reading_sum_non)
# A check if there is a difference between 2 correlations
cr <- cocor(~ x_out + y_out | x_non + y_non, data = list(outdf, nondf))
pval <- cr@fisher1925$p.value
res2 <- rbind(res2, cbind(var = n, correlation_changed = ifelse(pval < 0.05, "+", "-")))
}
res2
res <- inner_join(data.frame(res1),data.frame(res2),by="var")
# Adds a column - a condition for dropping or not the outliers
res$drop <- ifelse((res$distribution_changed == "+" & res$correlation_changed == "+") |
(res$distribution_changed == "-" & res$correlation_changed == "-"),
"No", "Yes")
# Remove 'meter_reading_sum' variable from the res data frame
res <- res[res$var != "meter_reading_sum", ]
res
drop_list <- res$var[res$drop == 'Yes']
outmat <- outlierMatrix(ff_train_agg)
for(n in drop_list){
# skip if there are no outliers in the column
if(length(ff_train_agg[which(outmat[[n]] == 1),n]) == 0){next}
# 'NA' at 'drop' column leads the variable to appear as 'NA' in 'drop_list' that leads to an error
if(is.na(n)){next}
ff_train_agg[which(outmat[[n]] == 1),n] <- NA
}
keep_list <- res$var[res$drop == 'No']
# Distribution of "square_feet_mode" has a medium range of values with a heavy tail - does not justify a log operation
vars_for_sqrt <- "square_feet_mode"
vars_for_categorization <- c('precip_depth_sum', 'precip_depth_max',
'dew_temperature_mean', 'dew_temperature_min',
'dew_temperature_max', 'rel_humid_mean', 'rel_humid_min',
'rel_humid_max', 'cloud_coverage_mode', 'cloud_coverage_max',
'elevation_mode')
outmat <- outlierMatrix(ff_train_agg)
for(n in keep_list){
if(is.na(n)){next}
# 'sqrt'
if (n %in% vars_for_sqrt){
ff_train_agg[which(outmat[[n]] == 1),n] <- sapply(ff_train_agg[which(outmat[[n]] == 1), n]
, FUN = (function(x){sqrt(x)}))
}
# categorization
else{
# Columns to be categorized
# Quartiles
Q1 <- quantile(ff_train_agg[[n]], 0.25, na.rm = TRUE)
Q2 <- quantile(ff_train_agg[[n]], 0.5, na.rm = TRUE)
Q3 <- quantile(ff_train_agg[[n]], 0.75, na.rm = TRUE)
if((Q1 != Q2) & (Q2 != Q3)) {
# The column is categorized into four categories (A, B, C, D) represent its 4 quartiles
# indicating the boundaries of the categories
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Q2, Q3, Inf),
# Specifies the labels to be assigned to each category
labels = c("A", "B", "C", "D"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q1 = Q2, Q1 does not function as a break
else if((Q1 == Q2) & (Q2 != Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q2, Q3, Inf),
labels = c("A", "B", "C"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q2 = Q3, Q3 does not function as a break
else if((Q1 != Q2) & (Q2 == Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Q2, Inf),
labels = c("A", "B", "C"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q1 = Q2 = Q3, Q2 and Q3 do not function as breaks
else if((Q1 == Q2) & (Q2 == Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Inf),
labels = c("A", "B"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
}
}
nominal_updated <- c(nominal, vars_for_categorization)
mm <- getMissingness(ff_train_agg)
mm
# Importing packages
library(readr)
library(visdat)
library(dplyr)
library(ggplot2)
library(psych)
library(odbc)
library(DBI)
library(dbscan)
library(naniar)
library(cocor)
library(gridExtra)
library(corrgram)
# 'mechkar' - written by Tomas Carpati
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/mechkar.R")
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/utils.R")
ff_train_agg <- data.frame(read.csv("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Data/CheckPoint2/ff_train_agg.csv"))
# nominal columns
nominal <- c("site_id", "building_id",
# all variables that start with 'sw' or 'is' (binary variables)
names(ff_train_agg)[grepl('^(sw|is)', names(ff_train_agg))])
# Cyclical variables (contain "_x_" or "_y_")
cyclical_vars <- names(ff_train_agg)[grep("_x_|_y_", names(ff_train_agg))]
# Excluding variables that outliers check is not relevant to them
vars_for_outliers <- names(ff_train_agg)[!names(ff_train_agg) %in% c(nominal, cyclical_vars, 'date')]
res1 <- NULL
outmat <- outlierMatrix(ff_train_agg)
# Excluding variables that outliers check is not relevant to them
for(n in vars_for_outliers){
n_out <- ff_train_agg[[n]]                           # 'n_out' includes outliers
n_non <- ff_train_agg[[n]][which(outmat[[n]] == 0)]  # 'which' returns indices
outnum <- length(n_out) - length(n_non)
pval <- suppressWarnings(ks.test(n_out, n_non)$p.value)
res1 <- rbind(res1, cbind(var = n, outliers_num = outnum,
distribution_changed = ifelse(pval < 0.05, "+", "-")))
}
res1
res2 <- NULL
outmat <- outlierMatrix(ff_train_agg)
# Excluding variables that outliers check is not relevant to them
for(n in vars_for_outliers){
out <- ff_train_agg[[n]]                         # data including outliers
non <- ff_train_agg[[n]][which(outmat[[n]] == 0)]  # data excluding outliers
# make sure that SD !=0 for the use of 'cocor' function
if(length(unique(non)) <= 1){next}
meter_reading_sum_out <- ff_train_agg$meter_reading_sum                # outcome including outliers
meter_reading_sum_non <- meter_reading_sum_out[which(outmat[[n]] == 0)]  # outcome excluding outliers
outdf <- data.frame(x_out = out,y_out = meter_reading_sum_out)
nondf <- data.frame(x_non = non,y_non = meter_reading_sum_non)
# A check if there is a difference between 2 correlations
cr <- cocor(~ x_out + y_out | x_non + y_non, data = list(outdf, nondf))
pval <- cr@fisher1925$p.value
res2 <- rbind(res2, cbind(var = n, correlation_changed = ifelse(pval < 0.05, "+", "-")))
}
res2
res <- inner_join(data.frame(res1),data.frame(res2),by="var")
# Adds a column - a condition for dropping or not the outliers
res$drop <- ifelse((res$distribution_changed == "+" & res$correlation_changed == "+") |
(res$distribution_changed == "-" & res$correlation_changed == "-"),
"No", "Yes")
# Remove 'meter_reading_sum' variable from the res data frame
res <- res[res$var != "meter_reading_sum", ]
res
drop_list <- res$var[res$drop == 'Yes']
outmat <- outlierMatrix(ff_train_agg)
for(n in drop_list){
# skip if there are no outliers in the column
if(length(ff_train_agg[which(outmat[[n]] == 1),n]) == 0){next}
# 'NA' at 'drop' column leads the variable to appear as 'NA' in 'drop_list' that leads to an error
if(is.na(n)){next}
ff_train_agg[which(outmat[[n]] == 1),n] <- NA
}
keep_list <- res$var[res$drop == 'No']
# Distribution of "square_feet_mode" has a medium range of values with a heavy tail - does not justify a log operation
vars_for_sqrt <- "square_feet_mode"
vars_for_categorization <- c('precip_depth_sum', 'precip_depth_max',
'dew_temperature_mean', 'dew_temperature_min',
'dew_temperature_max', 'rel_humid_mean', 'rel_humid_min',
'rel_humid_max', 'cloud_coverage_mode', 'cloud_coverage_max',
'elevation_mode')
outmat <- outlierMatrix(ff_train_agg)
for(n in keep_list){
if(is.na(n)){next}
# 'sqrt'
if (n %in% vars_for_sqrt){
ff_train_agg[which(outmat[[n]] == 1),n] <- sapply(ff_train_agg[which(outmat[[n]] == 1), n]
, FUN = (function(x){sqrt(x)}))
}
# categorization
else{
# Columns to be categorized
# Quartiles
Q1 <- quantile(ff_train_agg[[n]], 0.25, na.rm = TRUE)
Q2 <- quantile(ff_train_agg[[n]], 0.5, na.rm = TRUE)
Q3 <- quantile(ff_train_agg[[n]], 0.75, na.rm = TRUE)
if((Q1 != Q2) & (Q2 != Q3)) {
# The column is categorized into four categories (A, B, C, D) represent its 4 quartiles
# indicating the boundaries of the categories
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Q2, Q3, Inf),
# Specifies the labels to be assigned to each category
labels = c("A", "B", "C", "D"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q1 = Q2, Q1 does not function as a break
else if((Q1 == Q2) & (Q2 != Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q2, Q3, Inf),
labels = c("A", "B", "C"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q2 = Q3, Q3 does not function as a break
else if((Q1 != Q2) & (Q2 == Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Q2, Inf),
labels = c("A", "B", "C"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# When Q1 = Q2 = Q3, Q2 and Q3 do not function as breaks
else if((Q1 == Q2) & (Q2 == Q3)) {
ff_train_agg[[n]] <- cut(as.numeric(ff_train_agg[[n]]), breaks = c(-Inf, Q1, Inf),
labels = c("A", "B"))
ff_train_agg[[n]] <- as.character(ff_train_agg[[n]])
}
# Prior to using 'glm' function later on, 'factor' must be done to all variables that are categorized
ff_train_agg[[n]] <- factor(ff_train_agg[[n]])
}
}
nominal_updated <- c(nominal, vars_for_categorization)
mm <- getMissingness(ff_train_agg)
mm
# A new data frame of missing values
ff_train_agg_na <- missingMatrix(ff_train_agg)
ff_train_agg_na_rows <- ff_train_agg_na
# A new column - percent of missing values in each row
ff_train_agg_na_rows$pct <- (rowSums(ff_train_agg_na) / ncol(ff_train_agg_na)) * 100
# Groups the data by the "pct" column and counts the number of rows with each percentage of missing values
# Rows that have 50% or more of missing vakues will be dropped later
ff_train_agg_na_rows %>% group_by(pct) %>% tally
res3 <- NULL
for (m in mm$missingness$var) {
# Initializes an empty list that will be used to store the 'ggplot' objects that will be created in the following loop
p <- list()
# numeric values only
for (n in names(ff_train_agg[!names(ff_train_agg) %in% c('date', nominal_updated)])) {
if (n != m) {
miss <- ff_train_agg[[n]]
non <- ff_train_agg[[n]][which(ff_train_agg_na[[m]] == 0)]
missnum <- length(miss) - length(non)
pval <- suppressWarnings(ks.test(miss, non)$p.value)
res3 <- rbind(res3, cbind(missing = m, var = n, miss_cnt = missnum,
distribution_changed = ifelse(pval <= 0.05, "+", "-")))
}
}
}
res3 <- data.frame(res3)
res3
res4 <- res3 %>% filter(distribution_changed == "+")
mnar <- unique(res4$missing)
mnar
ff_train_agg$date <-  as.Date(ff_train_agg$date, format = "%Y-%m-%d")
# examination of missingness mechanism using 'glm'
# Measure the running time
start_time <- system.time({
res5 <- NULL
for(m in mm$missingness$var) {
ff <- ff_train_agg
# change the current examined variable values with its missing indicators
ff[[m]] <- ff_train_agg_na[[m]]
# 'glm' on all variables
#mod <- glm(ff[[m]] ~., data = ff, family = "binomial", maxit = 100, epsilon = 0.001)
# 'glm' on 'date' and 'nominal_updated' variables only. Those were excluded from ks.test before
mod <- glm(ff[[m]] ~., data = ff[, c('date', nominal_updated)], family = "binomial", maxit = 50, epsilon = 0.001)
sm <- summary(mod)
if(is.null(sm) == F) {  # a check
sm1 <- data.frame(var = row.names(sm$coefficients), pvalue = sm$coefficients[, 4])
res5 <- rbind(res5, cbind(m, sm1))
# append(res5, sm, m)
} else {
print(sm)
}
}
row.names(res5) <- NULL
res5
})
# Print the running time
print(paste("Running time:", start_time[3]))
res5
res5 %>% filter(pvalue <= 0.05)
# examination of missingness mechanism using 'glm'
# Measure the running time
start_time <- system.time({
res5 <- NULL
for(m in mm$missingness$var) {
ff <- ff_train_agg
# change the current examined variable values with its missing indicators
ff[[m]] <- ff_train_agg_na[[m]]
# 'glm' on all variables
#mod <- glm(ff[[m]] ~., data = ff, family = "binomial", maxit = 100, epsilon = 0.001)
# 'glm' on 'date' and 'nominal_updated' variables only. Those were excluded from ks.test before
mod <- glm(ff[[m]] ~., data = ff[, c('date', nominal_updated)], family = "binomial", maxit = 50, epsilon = 0.001)
sm <- summary(mod)
if(is.null(sm) == F) {  # a check
sm1 <- data.frame(var = row.names(sm$coefficients), pvalue = sm$coefficients[, 4])
res5 <- rbind(res5, cbind(m, sm1))
# append(res5, sm, m)
} else {
print(sm)
}
}
row.names(res5) <- NULL
res5
})
# Print the running time
print(paste("Running time:", start_time[3]))
res5 %>% filter(pvalue <= 0.05)
# examination of missingness mechanism using 'glm'
# Measure the running time
start_time <- system.time({
res5 <- NULL
for(m in mm$missingness$var) {
ff <- ff_train_agg
# change the current examined variable values with its missing indicators
ff[[m]] <- ff_train_agg_na[[m]]
# 'glm' on all variables
#mod <- glm(ff[[m]] ~., data = ff, family = "binomial", maxit = 100, epsilon = 0.001)
# 'glm' on 'date' and 'nominal_updated' variables only. Those were excluded from ks.test before
mod <- glm(ff[[m]] ~., data = ff[, c('date', nominal_updated)], family = "binomial", maxit = 50, epsilon = 0.0001)
sm <- summary(mod)
if(is.null(sm) == F) {  # a check
sm1 <- data.frame(var = row.names(sm$coefficients), pvalue = sm$coefficients[, 4])
res5 <- rbind(res5, cbind(m, sm1))
# append(res5, sm, m)
} else {
print(sm)
}
}
row.names(res5) <- NULL
res5
})
# Print the running time
print(paste("Running time:", start_time[3]))
res5 %>% filter(pvalue <= 0.05)
# examination of missingness mechanism using 'glm'
# Measure the running time
start_time <- system.time({
res5 <- NULL
for(m in mm$missingness$var) {
ff <- ff_train_agg
# change the current examined variable values with its missing indicators
ff[[m]] <- ff_train_agg_na[[m]]
# 'glm' on all variables
#mod <- glm(ff[[m]] ~., data = ff, family = "binomial", maxit = 100, epsilon = 0.001)
# 'glm' on 'date' and 'nominal_updated' variables only. Those were excluded from ks.test before
mod <- glm(ff[[m]] ~., data = ff[, c('date', nominal_updated)], family = "binomial", maxit = 50, epsilon = 0.00001)
sm <- summary(mod)
if(is.null(sm) == F) {  # a check
sm1 <- data.frame(var = row.names(sm$coefficients), pvalue = sm$coefficients[, 4])
res5 <- rbind(res5, cbind(m, sm1))
# append(res5, sm, m)
} else {
print(sm)
}
}
row.names(res5) <- NULL
res5
})
# Print the running time
print(paste("Running time:", start_time[3]))
res5$m %>% filter(pvalue <= 0.05)
res5 %>% filter(pvalue <= 0.05)
res5 %>% filter(pvalue <= 0.05) %>% res5$m
res5[pvalue <= 0.05, m]
res5['pvalue' <= 0.05, m]
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
unique_m
intersect(mnar, unique_m)
length(mnar)
intersect(mnar, unique_m)
length(mnar)
length(mnar)
intersect(mnar, unique_m)
ff_train_agg
ff_train_agg$precip_depth_max
filtered_res
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
unique_m
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
unique_m
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
unique_m
# Filter the rows where p-value <= 0.05
filtered_res <- res5[res5$pvalue <= 0.05, ]
# Get unique values of m
unique_m <- unique(filtered_res$m)
unique_m
# Importing packages
library(readr)
library(visdat)
library(dplyr)
library(ggplot2)
library(psych)
library(odbc)
library(DBI)
library(dbscan)
library(naniar)
library(cocor)
library(gridExtra)
library(corrgram)
# 'mechkar' - written by Tomas Carpati
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/mechkar.R")
source("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Scripts/R/utils.R")
ff_train_agg <- data.frame(read.csv("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Data/CheckPoint2/ff_train_agg.csv"))
# nominal columns
nominal <- c("site_id", "building_id",
# all variables that start with 'sw' or 'is' (binary variables)
names(ff_train_agg)[grepl('^(sw|is)', names(ff_train_agg))])
# Cyclical variables (contain "_x_" or "_y_")
cyclical_vars <- names(ff_train_agg)[grep("_x_|_y_", names(ff_train_agg))]
# Excluding variables that outliers check is not relevant to them
vars_for_outliers <- names(ff_train_agg)[!names(ff_train_agg) %in% c(nominal, cyclical_vars, 'date')]
# For runtime considerations, I will take a random sample of data
set.seed(1)
sample_df <- ff_train_agg %>% slice_sample(n = 50000)
# n = 50000: 5 minutes runtime
pdf("C:/Users/Avishai/Documents/General/Personal/DS Course/Google drive content/Projects/Final project-ASHRAE-Great Energy Predictor III/Graphs-before completion of data cleansing/scatter outliers graphs.pdf")
options(repr.plot.width = 8, repr.plot.height = 8)
par(mfrow=c(3,2))
outmat <- outlierMatrix(sample_df)
for (n in vars_for_outliers) {
n_out <- sample_df[[n]]
n_non <- sample_df[[n]][which(outmat[[n]] == 0)]
meter_reading_sum_out <- sample_df$meter_reading_sum
meter_reading_sum_non <- meter_reading_sum_out[which(outmat[[n]] == 0)]
outdf <- data.frame(x_out = n_out, y_out = meter_reading_sum_out)
nondf <- data.frame(x_non = n_non, y_non = meter_reading_sum_non)
# set the same limits for both plots for easier comparison
min_x_val <- min(c(n_out, n_non), na.rm = TRUE)
max_x_val <- max(c(n_out, n_non), na.rm = TRUE)
min_y_val <- min(c(meter_reading_sum_out, meter_reading_sum_non), na.rm = TRUE)
max_y_val <- max(c(meter_reading_sum_out, meter_reading_sum_non), na.rm = TRUE)
scatter.smooth(outdf$y_out ~ outdf$x_out, xlab = n, family = "symmetric",
xlim = c(min_x_val, max_x_val), ylim = c(min_y_val, max_y_val))
scatter.smooth(nondf$y_non ~ nondf$x_non, xlab = n, family = "symmetric",
xlim = c(min_x_val, max_x_val), ylim = c(min_y_val, max_y_val))
}
